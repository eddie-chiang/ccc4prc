{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597656769568",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import confuse\n",
    "import pandas\n",
    "\n",
    "from dialogueactclassification import Classifier\n",
    "\n",
    "cfg = confuse.LazyConfig('ccc4prc', __name__)\n",
    "# Add overrides on top of config.yaml for the workspace.\n",
    "cfg.set_file('./config.workspace.yaml')\n",
    "\n",
    "dataset_dir = Path(cfg['machine_learning']['labeled_seed_excel_file'].as_filename()).parent\n",
    "training_dataset_file = dataset_dir / ('training_dataset.csv')\n",
    "test_dataset_file = dataset_dir / ('test_dataset.csv')\n",
    "\n",
    "training_dataset = pandas.read_csv(training_dataset_file)\n",
    "test_dataset = pandas.read_csv(test_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from sklearn import metrics\n",
    "\n",
    "FEATURES = ['body', 'dialogue_act_classification_ml', 'comment_is_by_author']\n",
    "LABEL = 'code_comprehension_related'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Classifier Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.82550336 0.90441176 0.86315789       136\n         Yes  0.53571429 0.36585366 0.43478261        41\n\n    accuracy                      0.77966102       177\n   macro avg  0.68060882 0.63513271 0.64897025       177\nweighted avg  0.75837707 0.77966102 0.76392972       177\n\n"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "one_hot_encoder_categories = [\n",
    "    [\n",
    "        'Accept',\n",
    "        'Bye',\n",
    "        'Clarify',\n",
    "        'Continuer',\n",
    "        'Emotion',\n",
    "        'Emphasis',\n",
    "        'Greet',\n",
    "        'Other',\n",
    "        'Reject',\n",
    "        'Statement',\n",
    "        'System',\n",
    "        'whQuestion',\n",
    "        'yAnswer',\n",
    "        'nAnswer',\n",
    "        'ynQuestion'\n",
    "    ],\n",
    "    [\n",
    "        False,  # 0 should come before 1 for numerical columns.\n",
    "        True\n",
    "    ]\n",
    "]\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_pipeline', CountVectorizer(stop_words='english'), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_pipeline': 1.0,\n",
    "        'categorical_transformer': 1.0,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "classifier = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "X_train = training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evenly distribute the training data labelled as \"No\" and \"Yes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training DataSet - Label \"Yes\": 76 v.s. \"No\": 262, ratio: 0.2900763358778626\nTest Dataset - Label \"Yes\": 41 v.s. \"No\": 136, ratio: 0.3014705882352941\nTraining DataSet (evenly distributed) - Label \"Yes\": 76 v.s. \"No\": 76\n"
    }
   ],
   "source": [
    "min_label_count = y_train.value_counts().min()\n",
    "labelled_yes = training_dataset.loc[training_dataset[LABEL] == 'Yes'].head(min_label_count)\n",
    "labelled_no = training_dataset.loc[training_dataset[LABEL] == 'No'].head(min_label_count)\n",
    "evenly_distrubted_training_dataset = pandas.concat([labelled_yes, labelled_no])\n",
    "\n",
    "# Shuffle the order, in order to properly train the model.\n",
    "evenly_distrubted_training_dataset = evenly_distrubted_training_dataset.sample(frac=1)\n",
    "\n",
    "# Show the datasets value counts\n",
    "print(f'Training DataSet - Label \"Yes\": {len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(training_dataset.loc[training_dataset[LABEL] == \"No\"])}, ratio: {len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"])/len(training_dataset.loc[training_dataset[LABEL] == \"No\"])}')\n",
    "print(f'Test Dataset - Label \"Yes\": {len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(test_dataset.loc[test_dataset[LABEL] == \"No\"])}, ratio: {len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"])/len(test_dataset.loc[test_dataset[LABEL] == \"No\"])}')\n",
    "print(f'Training DataSet (evenly distributed) - Label \"Yes\": {len(evenly_distrubted_training_dataset.loc[evenly_distrubted_training_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(evenly_distrubted_training_dataset.loc[evenly_distrubted_training_dataset[LABEL] == \"No\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.90000000 0.59558824 0.71681416       136\n         Yes  0.36781609 0.78048780 0.50000000        41\n\n    accuracy                      0.63841808       177\n   macro avg  0.63390805 0.68803802 0.60840708       177\nweighted avg  0.77672576 0.63841808 0.66659167       177\n\n"
    }
   ],
   "source": [
    "# Performance after evenly distributed only the training dataset with labels \"No\" and \"Yes\".\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Performance after evenly distributed both the training and test datasets with labels \"No\" and \"Yes\".\n",
    "# But in practice, the incoming data is likely to be skewed to \"No\", so this is experiment only.\n",
    "# Evenly distribute the test data labelled as \"No\" and \"Yes\".\n",
    "min_label_count = y_true.value_counts().min()\n",
    "labelled_yes = test_dataset.loc[test_dataset[LABEL] == 'Yes'].head(min_label_count)\n",
    "labelled_no = test_dataset.loc[test_dataset[LABEL] == 'No'].head(min_label_count)\n",
    "evenly_distrubted_test_dataset = pandas.concat([labelled_yes, labelled_no])\n",
    "\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = evenly_distrubted_test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = evenly_distrubted_test_dataset[LABEL]\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - using a different vectorization - TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "one_hot_encoder_categories = [\n",
    "    [\n",
    "        'Accept',\n",
    "        'Bye',\n",
    "        'Clarify',\n",
    "        'Continuer',\n",
    "        'Emotion',\n",
    "        'Emphasis',\n",
    "        'Greet',\n",
    "        'Other',\n",
    "        'Reject',\n",
    "        'Statement',\n",
    "        'System',\n",
    "        'whQuestion',\n",
    "        'yAnswer',\n",
    "        'nAnswer',\n",
    "        'ynQuestion'\n",
    "    ],\n",
    "    [\n",
    "        False,  # 0 should come before 1 for numerical columns.\n",
    "        True\n",
    "    ]\n",
    "]\n",
    "\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.92708333 0.65441176 0.76724138       136\n         Yes  0.41975309 0.82926829 0.55737705        41\n\n    accuracy                      0.69491525       177\n   macro avg  0.67341821 0.74184003 0.66230921       177\nweighted avg  0.80956616 0.69491525 0.71862874       177\n\n"
    }
   ],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 3.8,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - add Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.92473118 0.63235294 0.75109170       136\n         Yes  0.40476190 0.82926829 0.54400000        41\n\n    accuracy                      0.67796610       177\n   macro avg  0.66474654 0.73081062 0.64754585       177\nweighted avg  0.80428632 0.67796610 0.70312131       177\n\n"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "class StemmedCountVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', StemmedCountVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 3.8,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try adding Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.90425532 0.62500000 0.73913043       136\n         Yes  0.38554217 0.78048780 0.51612903        41\n\n    accuracy                      0.66101695       177\n   macro avg  0.64489874 0.70274390 0.62762973       177\nweighted avg  0.78410143 0.66101695 0.68747474       177\n\n"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 3.8,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.91566265 0.55882353 0.69406393       136\n         Yes  0.36170213 0.82926829 0.50370370        41\n\n    accuracy                      0.62146893       177\n   macro avg  0.63868239 0.69404591 0.59888382       177\nweighted avg  0.78734411 0.62146893 0.64996919       177\n\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 10,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', MultinomialNB(fit_prior=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.92134831 0.60294118 0.72888889       136\n         Yes  0.38636364 0.82926829 0.52713178        41\n\n    accuracy                      0.65536723       177\n   macro avg  0.65385598 0.71610473 0.62801034       177\nweighted avg  0.79742531 0.65536723 0.68215419       177\n\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 10,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', LogisticRegression())],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.91304348 0.61764706 0.73684211       136\n         Yes  0.38823529 0.80487805 0.52380952        41\n\n    accuracy                      0.66101695       177\n   macro avg  0.65063939 0.71126255 0.63032581       177\nweighted avg  0.79147774 0.66101695 0.68749558       177\n\n"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 10,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', DecisionTreeClassifier())],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'preprocessor__transformer_weights': {'body_bow_vectorizer': 2,\n  'categorical_transformer': 1}}"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 10,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.precision_score, pos_label=\"Yes\")\n",
    "\n",
    "grid_search_cv_params = [\n",
    "    {\n",
    "        'preprocessor__transformer_weights': [\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 4},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 6},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 10},\n",
    "            {'body_bow_vectorizer': 2, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 4, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 6, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 10, 'categorical_transformer': 1},                                      \n",
    "        ]\n",
    "    },\n",
    "    {'preprocessor__body_bow_vectorizer__stop_words': [None, 'english']},\n",
    "    {'preprocessor__body_bow_vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 5), (2, 2), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5)]},\n",
    "    {'classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
    "    {'classifier__C': [0.8, 1, 1.2, 2, 4]},    \n",
    "]\n",
    "classifier = GridSearchCV(full_pipeline, param_grid=grid_search_cv_params, cv=5, scoring=scorer)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.90625000 0.63970588 0.75000000       136\n         Yes  0.39506173 0.78048780 0.52459016        41\n\n    accuracy                      0.67231638       177\n   macro avg  0.65065586 0.71009684 0.63729508       177\nweighted avg  0.78783916 0.67231638 0.69778642       177\n\n"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}