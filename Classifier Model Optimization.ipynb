{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597665936295",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import confuse\n",
    "import pandas\n",
    "\n",
    "from dialogueactclassification import Classifier\n",
    "\n",
    "cfg = confuse.LazyConfig('ccc4prc', __name__)\n",
    "# Add overrides on top of config.yaml for the workspace.\n",
    "cfg.set_file('./config.workspace.yaml')\n",
    "\n",
    "dataset_dir = Path(cfg['machine_learning']['labeled_seed_excel_file'].as_filename()).parent\n",
    "training_dataset_file = dataset_dir / ('training_dataset.csv')\n",
    "test_dataset_file = dataset_dir / ('test_dataset.csv')\n",
    "\n",
    "training_dataset = pandas.read_csv(training_dataset_file)\n",
    "test_dataset = pandas.read_csv(test_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from sklearn import metrics\n",
    "\n",
    "FEATURES = ['body', 'dialogue_act_classification_ml', 'comment_is_by_author']\n",
    "LABEL = 'code_comprehension_related'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Classifier Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.82781457 0.91240876 0.86805556       137\n         Yes  0.53846154 0.35000000 0.42424242        40\n\n    accuracy                      0.78531073       177\n   macro avg  0.68313805 0.63120438 0.64614899       177\nweighted avg  0.76242405 0.78531073 0.76775880       177\n\n"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "one_hot_encoder_categories = [\n",
    "    [\n",
    "        'Accept',\n",
    "        'Bye',\n",
    "        'Clarify',\n",
    "        'Continuer',\n",
    "        'Emotion',\n",
    "        'Emphasis',\n",
    "        'Greet',\n",
    "        'Other',\n",
    "        'Reject',\n",
    "        'Statement',\n",
    "        'System',\n",
    "        'whQuestion',\n",
    "        'yAnswer',\n",
    "        'nAnswer',\n",
    "        'ynQuestion'\n",
    "    ],\n",
    "    [\n",
    "        False,  # 0 should come before 1 for numerical columns.\n",
    "        True\n",
    "    ]\n",
    "]\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_pipeline', CountVectorizer(stop_words='english'), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_pipeline': 1.0,\n",
    "        'categorical_transformer': 1.0,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "classifier = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "X_train = training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evenly distribute the training data labelled as \"No\" and \"Yes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training DataSet - Label \"Yes\": 67 v.s. \"No\": 271, ratio: 0.24723247232472326\nTest Dataset - Label \"Yes\": 40 v.s. \"No\": 137, ratio: 0.291970802919708\nTraining DataSet (evenly distributed) - Label \"Yes\": 67 v.s. \"No\": 67\n"
    }
   ],
   "source": [
    "min_label_count = y_train.value_counts().min()\n",
    "labelled_yes = training_dataset.loc[training_dataset[LABEL] == 'Yes'].head(min_label_count)\n",
    "labelled_no = training_dataset.loc[training_dataset[LABEL] == 'No'].head(min_label_count)\n",
    "evenly_distrubted_training_dataset = pandas.concat([labelled_yes, labelled_no])\n",
    "\n",
    "# Shuffle the order, in order to properly train the model.\n",
    "evenly_distrubted_training_dataset = evenly_distrubted_training_dataset.sample(frac=1)\n",
    "\n",
    "# Show the datasets value counts\n",
    "print(f'Training DataSet - Label \"Yes\": {len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(training_dataset.loc[training_dataset[LABEL] == \"No\"])}, ratio: {len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"])/len(training_dataset.loc[training_dataset[LABEL] == \"No\"])}')\n",
    "print(f'Test Dataset - Label \"Yes\": {len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(test_dataset.loc[test_dataset[LABEL] == \"No\"])}, ratio: {len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"])/len(test_dataset.loc[test_dataset[LABEL] == \"No\"])}')\n",
    "print(f'Training DataSet (evenly distributed) - Label \"Yes\": {len(evenly_distrubted_training_dataset.loc[evenly_distrubted_training_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(evenly_distrubted_training_dataset.loc[evenly_distrubted_training_dataset[LABEL] == \"No\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.92682927 0.55474453 0.69406393       137\n         Yes  0.35789474 0.85000000 0.50370370        40\n\n    accuracy                      0.62146893       177\n   macro avg  0.64236200 0.70237226 0.59888382       177\nweighted avg  0.79825649 0.62146893 0.65104467       177\n\n"
    }
   ],
   "source": [
    "# Performance after evenly distributed only the training dataset with labels \"No\" and \"Yes\".\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Performance after evenly distributed both the training and test datasets with labels \"No\" and \"Yes\".\n",
    "# But in practice, the incoming data is likely to be skewed to \"No\", so this is experiment only.\n",
    "# Evenly distribute the test data labelled as \"No\" and \"Yes\".\n",
    "min_label_count = y_true.value_counts().min()\n",
    "labelled_yes = test_dataset.loc[test_dataset[LABEL] == 'Yes'].head(min_label_count)\n",
    "labelled_no = test_dataset.loc[test_dataset[LABEL] == 'No'].head(min_label_count)\n",
    "evenly_distrubted_test_dataset = pandas.concat([labelled_yes, labelled_no])\n",
    "\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = evenly_distrubted_test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = evenly_distrubted_test_dataset[LABEL]\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - using a different vectorization - TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "one_hot_encoder_categories = [\n",
    "    [\n",
    "        'Accept',\n",
    "        'Bye',\n",
    "        'Clarify',\n",
    "        'Continuer',\n",
    "        'Emotion',\n",
    "        'Emphasis',\n",
    "        'Greet',\n",
    "        'Other',\n",
    "        'Reject',\n",
    "        'Statement',\n",
    "        'System',\n",
    "        'whQuestion',\n",
    "        'yAnswer',\n",
    "        'nAnswer',\n",
    "        'ynQuestion'\n",
    "    ],\n",
    "    [\n",
    "        False,  # 0 should come before 1 for numerical columns.\n",
    "        True\n",
    "    ]\n",
    "]\n",
    "\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.94382022 0.61313869 0.74336283       137\n         Yes  0.39772727 0.87500000 0.54687500        40\n\n    accuracy                      0.67231638       177\n   macro avg  0.67077375 0.74406934 0.64511892       177\nweighted avg  0.82040939 0.67231638 0.69895880       177\n\n"
    }
   ],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "        # ('author_transformer', OneHotEncoder(categories=[[False, True]]), ['comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 3.8,\n",
    "        # 'author_transformer': 0,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - add Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.94382022 0.61313869 0.74336283       137\n         Yes  0.39772727 0.87500000 0.54687500        40\n\n    accuracy                      0.67231638       177\n   macro avg  0.67077375 0.74406934 0.64511892       177\nweighted avg  0.82040939 0.67231638 0.69895880       177\n\n"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "class StemmedCountVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', StemmedCountVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 3.8,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try adding Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.96039604 0.70802920 0.81512605       137\n         Yes  0.47368421 0.90000000 0.62068966        40\n\n    accuracy                      0.75141243       177\n   macro avg  0.71704013 0.80401460 0.71790785       177\nweighted avg  0.85040467 0.75141243 0.77118562       177\n\n"
    }
   ],
   "source": [
    "from nlp import LemmaTokenizer\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words=None, ngram_range=(1, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 3,\n",
    "        'categorical_transformer': 1,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.92857143 0.56934307 0.70588235       137\n         Yes  0.36559140 0.85000000 0.51127820        40\n\n    accuracy                      0.63276836       177\n   macro avg  0.64708141 0.70967153 0.60858027       177\nweighted avg  0.80134430 0.63276836 0.66190401       177\n\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 10,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', MultinomialNB(fit_prior=True))],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.92941176 0.57664234 0.71171171       137\n         Yes  0.36956522 0.85000000 0.51515152        40\n\n    accuracy                      0.63841808       177\n   macro avg  0.64948849 0.71332117 0.61343161       177\nweighted avg  0.80289277 0.63841808 0.66729133       177\n\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 10,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', LogisticRegression())],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.87368421 0.60583942 0.71551724       137\n         Yes  0.34146341 0.70000000 0.45901639        40\n\n    accuracy                      0.62711864       177\n   macro avg  0.60757381 0.65291971 0.58726682       177\nweighted avg  0.75340832 0.62711864 0.65755095       177\n\n"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 10,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', DecisionTreeClassifier())],\n",
    "    verbose=False)\n",
    "\n",
    "classifier = full_pipeline\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'preprocessor__transformer_weights': {'body_bow_vectorizer': 4,\n  'categorical_transformer': 1}}"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words=None, ngram_range=(1, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 3,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.precision_score, pos_label=\"Yes\")\n",
    "\n",
    "grid_search_cv_params = [\n",
    "    {\n",
    "        'preprocessor__transformer_weights': [\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 4},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 6},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 10},\n",
    "            {'body_bow_vectorizer': 2, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 4, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 6, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 10, 'categorical_transformer': 1},                                      \n",
    "        ]\n",
    "    },\n",
    "    {'preprocessor__body_bow_vectorizer__stop_words': [None, 'english']},\n",
    "    {'preprocessor__body_bow_vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 5), (2, 2), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5)]},\n",
    "    {'classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
    "    {'classifier__C': [0.8, 1, 1.2, 2, 4]},    \n",
    "]\n",
    "classifier = GridSearchCV(full_pipeline, param_grid=grid_search_cv_params, cv=5, scoring='accuracy')\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.94174757 0.70802920 0.80833333       137\n         Yes  0.45945946 0.85000000 0.59649123        40\n\n    accuracy                      0.74011299       177\n   macro avg  0.70060352 0.77901460 0.70241228       177\nweighted avg  0.83275591 0.74011299 0.76045941       177\n\n"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}