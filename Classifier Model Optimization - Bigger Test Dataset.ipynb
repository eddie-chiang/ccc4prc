{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598275370267",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import confuse\n",
    "import pandas\n",
    "\n",
    "from classifier import DialogueActClassifierFactory\n",
    "\n",
    "cfg = confuse.LazyConfig('ccc4prc', __name__)\n",
    "# Add overrides on top of config.yaml for the workspace.\n",
    "cfg.set_file('./config.workspace.yaml')\n",
    "\n",
    "dac_factory = DialogueActClassifierFactory()\n",
    "dac_labels = dac_factory.get_classifier(\n",
    "    Path(cfg['dialogue_act_classification']['classifier_file'].as_filename()),\n",
    "    cfg['dialogue_act_classification']['test_set_percentage'].as_number()).labels()\n",
    "\n",
    "dataset_dir = Path(cfg['machine_learning']['labeled_seed_excel_file'].as_filename()).parent\n",
    "training_dataset_file = dataset_dir / ('training_dataset.csv')\n",
    "test_dataset_file = dataset_dir / ('test_dataset.csv')\n",
    "\n",
    "training_dataset = pandas.read_csv(training_dataset_file)\n",
    "test_dataset = pandas.read_csv(test_dataset_file).head(353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from sklearn import metrics\n",
    "\n",
    "FEATURES = ['body', 'dialogue_act_classification_ml', 'comment_is_by_author']\n",
    "LABEL = 'code_comprehension_related'\n",
    "report_dict_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialogue Act Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Precision    Recall  Accuracy\n                  NaN       NaN  0.666667\nStatement    0.666667  0.593023       NaN\nEmotion      0.989247  0.666667       NaN\nSystem       0.951456  0.911628       NaN\nGreet        1.000000  0.804878       NaN\nAccept       0.615385  0.216216       NaN\nReject       0.157895  0.166667       NaN\nwhQuestion   0.746269  0.769231       NaN\nContinuer    0.000000  0.000000       NaN\nynQuestion   0.671429  0.734375       NaN\nyAnswer      0.363636  0.666667       NaN\nBye          0.739130  0.894737       NaN\nClarify      0.000000  0.000000       NaN\nEmphasis     0.386364  0.500000       NaN\nnAnswer      0.000000  0.000000       NaN\nOther        0.000000  0.000000       NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th></th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>Statement</th>\n      <td>0.666667</td>\n      <td>0.593023</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Emotion</th>\n      <td>0.989247</td>\n      <td>0.666667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>System</th>\n      <td>0.951456</td>\n      <td>0.911628</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Greet</th>\n      <td>1.000000</td>\n      <td>0.804878</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Accept</th>\n      <td>0.615385</td>\n      <td>0.216216</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Reject</th>\n      <td>0.157895</td>\n      <td>0.166667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>whQuestion</th>\n      <td>0.746269</td>\n      <td>0.769231</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Continuer</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ynQuestion</th>\n      <td>0.671429</td>\n      <td>0.734375</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>yAnswer</th>\n      <td>0.363636</td>\n      <td>0.666667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Bye</th>\n      <td>0.739130</td>\n      <td>0.894737</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Clarify</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Emphasis</th>\n      <td>0.386364</td>\n      <td>0.500000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>nAnswer</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Other</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "precisions, recalls = dac_factory.get_precision_and_recall()\n",
    "precisions_recalls = [precisions, recalls]\n",
    "\n",
    "dac_report = {}\n",
    "dac_report[''] = [None, None, dac_factory.get_accuracy()]\n",
    "for label in precisions.keys():\n",
    "  dac_report[label] = [i[label] for i in precisions_recalls]\n",
    "\n",
    "df = DataFrame.from_dict(dac_report, orient='index', columns=['Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Classifier Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "one_hot_encoder_categories = [\n",
    "    dac_labels,\n",
    "    [\n",
    "        False,  # 0 should come before 1 for numerical columns.\n",
    "        True\n",
    "    ]\n",
    "]\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_pipeline', CountVectorizer(stop_words='english'), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_pipeline': 1.0,\n",
    "        'categorical_transformer': 1.0,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "clf_original = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "X_train = training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "clf_original.fit(X_train, y_train)\n",
    "y_pred = clf_original.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'Original (CountVectorizer)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evenly distribute the training data labelled as \"No\" and \"Yes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_label_count = y_train.value_counts().min()\n",
    "labelled_yes = training_dataset.loc[training_dataset[LABEL] == 'Yes'].head(min_label_count)\n",
    "labelled_no = training_dataset.loc[training_dataset[LABEL] == 'No'].head(min_label_count)\n",
    "evenly_distrubted_training_dataset = pandas.concat([labelled_yes, labelled_no])\n",
    "\n",
    "# Shuffle the order, in order to properly train the model.\n",
    "evenly_distrubted_training_dataset = evenly_distrubted_training_dataset.sample(frac=1)\n",
    "\n",
    "# Show the datasets value counts\n",
    "print(f'Training DataSet - Label \"Yes\": {len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(training_dataset.loc[training_dataset[LABEL] == \"No\"])}, ratio: {len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"])/len(training_dataset.loc[training_dataset[LABEL] == \"No\"])}')\n",
    "print(f'Test Dataset - Label \"Yes\": {len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(test_dataset.loc[test_dataset[LABEL] == \"No\"])}, ratio: {len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"])/len(test_dataset.loc[test_dataset[LABEL] == \"No\"])}')\n",
    "print(f'Training DataSet (evenly distributed) - Label \"Yes\": {len(evenly_distrubted_training_dataset.loc[evenly_distrubted_training_dataset[LABEL] == \"Yes\"])} v.s. \"No\": {len(evenly_distrubted_training_dataset.loc[evenly_distrubted_training_dataset[LABEL] == \"No\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performance after evenly distributed only the training dataset with labels \"No\" and \"Yes\".\n",
    "X_train_evenly_distributed = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train_evenly_distributed = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "clf_original.fit(X_train_evenly_distributed, y_train_evenly_distributed)\n",
    "y_pred = clf_original.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'Original (CountVectorizer + Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Performance after evenly distributed both the training and test datasets with labels \"No\" and \"Yes\".\n",
    "# But in practice, the incoming data is likely to be skewed to \"No\", so this is experiment only.\n",
    "# Evenly distribute the test data labelled as \"No\" and \"Yes\".\n",
    "min_label_count = y_true.value_counts().min()\n",
    "labelled_yes = test_dataset.loc[test_dataset[LABEL] == 'Yes'].head(min_label_count)\n",
    "labelled_no = test_dataset.loc[test_dataset[LABEL] == 'No'].head(min_label_count)\n",
    "evenly_distrubted_test_dataset = pandas.concat([labelled_yes, labelled_no])\n",
    "\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = evenly_distrubted_test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = evenly_distrubted_test_dataset[LABEL]\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - using a different vectorization - TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train = evenly_distrubted_training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = evenly_distrubted_training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "        # ('author_transformer', OneHotEncoder(categories=[[False, True]]), ['comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 3,\n",
    "        'categorical_transformer': 1,\n",
    "        # 'author_transformer': 0,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc = full_pipeline\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'TDIDF': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - add Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "class StemmedCountVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', StemmedCountVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 3,\n",
    "        'categorical_transformer': 1,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc = full_pipeline\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'TDIDF+Stemming': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try adding Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nlp import LemmaTokenizer\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words=None, ngram_range=(1, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 3,\n",
    "        'categorical_transformer': 1,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc = full_pipeline\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'TDIDF+Lemmatization': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 3,\n",
    "        'categorical_transformer': 1,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', MultinomialNB(fit_prior=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_multinominal_nb = full_pipeline\n",
    "\n",
    "clf_multinominal_nb.fit(X_train, y_train)\n",
    "y_pred = clf_multinominal_nb.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'MultinomialNB': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 3,\n",
    "        'categorical_transformer': 1,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', LogisticRegression())],\n",
    "    verbose=False)\n",
    "\n",
    "clf_logistic_regression = full_pipeline\n",
    "\n",
    "clf_logistic_regression.fit(X_train, y_train)\n",
    "y_pred = clf_logistic_regression.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'LogisticRegression': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning - try using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 3,\n",
    "        'categorical_transformer': 1,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', DecisionTreeClassifier())],\n",
    "    verbose=False)\n",
    "\n",
    "clf_decision_treee = full_pipeline\n",
    "\n",
    "clf_decision_treee.fit(X_train, y_train)\n",
    "y_pred = clf_decision_treee.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'DecisionTree': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_bow_vectorizer', TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words=None, ngram_range=(1, 2)), 'body'),\n",
    "        ('categorical_transformer', OneHotEncoder(categories=one_hot_encoder_categories),\n",
    "            ['dialogue_act_classification_ml', 'comment_is_by_author']),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_bow_vectorizer': 1,\n",
    "        'categorical_transformer': 3,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.precision_score, pos_label=\"Yes\")\n",
    "\n",
    "grid_search_cv_params = [\n",
    "    {\n",
    "        'preprocessor__transformer_weights': [\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 4},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 6},\n",
    "            {'body_bow_vectorizer': 1, 'categorical_transformer': 10},\n",
    "            {'body_bow_vectorizer': 2, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 4, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 6, 'categorical_transformer': 1},\n",
    "            {'body_bow_vectorizer': 10, 'categorical_transformer': 1},                                      \n",
    "        ]\n",
    "    },\n",
    "    {'preprocessor__body_bow_vectorizer__stop_words': [None, 'english']},\n",
    "    {'preprocessor__body_bow_vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 5), (2, 2), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5)]},\n",
    "    {'classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
    "    {'classifier__C': [0.8, 1, 1.2, 2, 4]},    \n",
    "]\n",
    "clf_grid_search_cv = GridSearchCV(full_pipeline, param_grid=grid_search_cv_params, cv=5, scoring='accuracy')\n",
    "\n",
    "clf_grid_search_cv.fit(X_train, y_train)\n",
    "clf_grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf_grid_search_cv.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'TDIDF+GridSearch': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from classifier import CodeComprehensionClassifierFactory\n",
    "\n",
    "clf_optimal = CodeComprehensionClassifierFactory.get_classifier(dac_labels)\n",
    "\n",
    "clf_optimal.fit(X_train, y_train)\n",
    "y_pred = clf_optimal.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "print(report)\n",
    "report_dict_list.append({'CodeComprehensionClassifierFactory': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Result Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "x = [next(iter(report.keys())) for report in report_dict_list]\n",
    "\n",
    "df = DataFrame({\n",
    "    'Algorithms': x,\n",
    "    'no_precision': [next(iter(report.values()))['No']['precision'] for report in report_dict_list],\n",
    "    'no_recall': [next(iter(report.values()))['No']['recall'] for report in report_dict_list],\n",
    "    'no_f1_score': [next(iter(report.values()))['No']['f1-score'] for report in report_dict_list],\n",
    "    'yes_precision': [next(iter(report.values()))['Yes']['precision'] for report in report_dict_list],\n",
    "    'yes_recall': [next(iter(report.values()))['Yes']['recall'] for report in report_dict_list],\n",
    "    'yes_f1_score': [next(iter(report.values()))['Yes']['f1-score'] for report in report_dict_list],\n",
    "    'Accuracy': [next(iter(report.values()))['accuracy'] for report in report_dict_list]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyplot.style.context('seaborn-white'):\n",
    "    df.plot.bar(x='Algorithms', y='yes_f1_score', rot=90, title='Algorithms v.s. F1-Score (Label \"Yes\")', color='red', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='yes_precision', rot=90, title='Algorithms v.s. Precision (Label \"Yes\")', color='orange', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='yes_recall', rot=90, title='Algorithms v.s. Recall (Label \"Yes\")', color='brown', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='no_f1_score', rot=90, title='Algorithms v.s. F1-Score (Label \"No\")', color='green', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='no_precision', rot=90, title='Algorithms v.s. Precision (Label \"No\")', color='blue', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='no_recall', rot=90, title='Algorithms v.s. Recall (Label \"No\")', color='magenta', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='Accuracy', rot=90, title='Algorithms v.s. Accurracy', color='purple', legend=False)\n",
    "\n",
    "    # axes = df.plot.bar(rot=90, title=\"Algorithms Performance\", subplots=True)\n",
    "\n",
    "    pyplot.show(block=False)"
   ]
  }
 ]
}