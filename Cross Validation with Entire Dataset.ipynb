{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599017660668",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "from pathlib import Path\n",
    "\n",
    "import confuse\n",
    "import pandas\n",
    "\n",
    "from classifier import DialogueActClassifierFactory\n",
    "from pandas import DataFrame\n",
    "from sklearn import metrics\n",
    "\n",
    "cfg = confuse.LazyConfig('ccc4prc', __name__)\n",
    "# Add overrides on top of config.yaml for the workspace.\n",
    "cfg.set_file('./config.workspace.yaml')\n",
    "\n",
    "dac_factory = DialogueActClassifierFactory()\n",
    "dac_labels = dac_factory.get_classifier(\n",
    "    Path(cfg['dialogue_act_classification']['classifier_file'].as_filename()),\n",
    "    cfg['dialogue_act_classification']['test_set_percentage'].as_number()).labels()\n",
    "\n",
    "dataset_dir = Path(cfg['machine_learning']['labeled_seed_excel_file'].as_filename()).parent\n",
    "training_dataset_file = dataset_dir / ('training_dataset.csv')\n",
    "test_dataset_file = dataset_dir / ('test_dataset.csv')\n",
    "\n",
    "training_dataset = pandas.read_csv(training_dataset_file)\n",
    "test_dataset = pandas.read_csv(test_dataset_file)\n",
    "\n",
    "FEATURES = ['body', 'dialogue_act_classification_ml', 'comment_is_by_author']\n",
    "LABEL = 'code_comprehension_related'\n",
    "\n",
    "entire_dataset = pandas.concat([training_dataset, test_dataset], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "is_author_categories = [\n",
    "    False,  # 0 should come before 1 for numerical columns.\n",
    "    True\n",
    "]\n",
    "\n",
    "from nlp import LemmaTokenizer\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            'body_tdidf_vectorizer',\n",
    "            TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', ngram_range=(1, 2)),\n",
    "            'body'\n",
    "        ),\n",
    "        (\n",
    "            'dac_transformer',\n",
    "            OneHotEncoder(categories=[dac_labels]),\n",
    "            ['dialogue_act_classification_ml']\n",
    "        ),\n",
    "        (\n",
    "            'is_author_transformer',\n",
    "            OneHotEncoder(categories=[is_author_categories]),\n",
    "            ['comment_is_by_author']\n",
    "        ),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_tdidf_vectorizer': 4,\n",
    "        'dac_transformer': 1,\n",
    "        'is_author_transformer': 2,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', LogisticRegression(C=500000, solver='lbfgs'))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_logistic_regression = full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance with splitting into Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.92879257 0.95238095 0.94043887       315\n         Yes  0.75806452 0.67142857 0.71212121        70\n\n    accuracy                      0.90129870       385\n   macro avg  0.84342854 0.81190476 0.82628004       385\nweighted avg  0.89775111 0.90129870 0.89892657       385\n\n"
    }
   ],
   "source": [
    "X_train = training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "clf_logistic_regression.fit(X_train, y_train)\n",
    "y_pred = clf_logistic_regression.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_true, y_pred, digits=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance with an Entire Dataset and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.53846154 0.44444444 0.5        0.61538462 0.74193548]\nMin: 0.4444444444444445, Mean: 0.5680452164323132, Max: 0.7419354838709677\n"
    }
   ],
   "source": [
    "X = entire_dataset[FEATURES]\n",
    "y = entire_dataset[LABEL]\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "yes_f1_scorer = metrics.make_scorer(metrics.f1_score, pos_label=\"Yes\")\n",
    "\n",
    "scores = cross_val_score(clf_logistic_regression, X, y, cv=5, scoring=yes_f1_scorer, n_jobs=-1)\n",
    "print(scores)\n",
    "scores = pandas.Series(scores)\n",
    "print(f'Min: {scores.min()}, Mean: {scores.mean()}, Max: {scores.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n          No  0.89596273 0.92320000 0.90937746       625\n         Yes  0.61904762 0.53793103 0.57564576       145\n\n    accuracy                      0.85064935       770\n   macro avg  0.75750518 0.73056552 0.74251161       770\nweighted avg  0.84381638 0.85064935 0.84653188       770\n\n"
    }
   ],
   "source": [
    "y_pred = cross_val_predict(clf_logistic_regression, X, y, cv=5, n_jobs=-1)\n",
    "print(metrics.classification_report(y, y_pred, digits=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}