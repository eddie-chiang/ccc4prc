{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "f5a82c895b952811f2926d68cfc89186839a1a1d54c5d848ca92980e11e908ef"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "from pathlib import Path\n",
    "\n",
    "import confuse\n",
    "import pandas\n",
    "\n",
    "from classifier import DialogueActClassifierFactory\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from sklearn import metrics\n",
    "\n",
    "cfg = confuse.LazyConfig('ccc4prc', __name__)\n",
    "# Add overrides on top of config.yaml for the workspace.\n",
    "cfg.set_file('./config.workspace.yaml')\n",
    "\n",
    "dac_factory = DialogueActClassifierFactory()\n",
    "dac_labels = dac_factory.get_classifier(\n",
    "    Path(cfg['dialogue_act_classification']['classifier_file'].as_filename()),\n",
    "    cfg['dialogue_act_classification']['test_set_percentage'].as_number()).labels()\n",
    "\n",
    "dataset_dir = Path(cfg['machine_learning']['labeled_seed_excel_file'].as_filename()).parent\n",
    "training_dataset_file = dataset_dir / ('training_dataset.csv')\n",
    "test_dataset_file = dataset_dir / ('test_dataset.csv')\n",
    "\n",
    "training_dataset = pandas.read_csv(training_dataset_file)\n",
    "test_dataset = pandas.read_csv(test_dataset_file)\n",
    "\n",
    "FEATURES = ['body', 'dialogue_act_classification_ml', 'comment_is_by_author']\n",
    "LABEL = 'code_comprehension_related'\n",
    "report_dict_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialogue Act Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Precision    Recall  Accuracy\n",
       "                  NaN       NaN  0.666667\n",
       "Statement    0.666667  0.593023       NaN\n",
       "Emotion      0.989247  0.666667       NaN\n",
       "System       0.951456  0.911628       NaN\n",
       "Greet        1.000000  0.804878       NaN\n",
       "Accept       0.615385  0.216216       NaN\n",
       "Reject       0.157895  0.166667       NaN\n",
       "whQuestion   0.746269  0.769231       NaN\n",
       "Continuer    0.000000  0.000000       NaN\n",
       "ynQuestion   0.671429  0.734375       NaN\n",
       "yAnswer      0.363636  0.666667       NaN\n",
       "Bye          0.739130  0.894737       NaN\n",
       "Clarify      0.000000  0.000000       NaN\n",
       "Emphasis     0.386364  0.500000       NaN\n",
       "nAnswer      0.000000  0.000000       NaN\n",
       "Other        0.000000  0.000000       NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th></th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>Statement</th>\n      <td>0.666667</td>\n      <td>0.593023</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Emotion</th>\n      <td>0.989247</td>\n      <td>0.666667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>System</th>\n      <td>0.951456</td>\n      <td>0.911628</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Greet</th>\n      <td>1.000000</td>\n      <td>0.804878</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Accept</th>\n      <td>0.615385</td>\n      <td>0.216216</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Reject</th>\n      <td>0.157895</td>\n      <td>0.166667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>whQuestion</th>\n      <td>0.746269</td>\n      <td>0.769231</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Continuer</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ynQuestion</th>\n      <td>0.671429</td>\n      <td>0.734375</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>yAnswer</th>\n      <td>0.363636</td>\n      <td>0.666667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Bye</th>\n      <td>0.739130</td>\n      <td>0.894737</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Clarify</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Emphasis</th>\n      <td>0.386364</td>\n      <td>0.500000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>nAnswer</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Other</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "precisions, recalls = dac_factory.get_precision_and_recall()\n",
    "precisions_recalls = [precisions, recalls]\n",
    "\n",
    "dac_report = {}\n",
    "dac_report[''] = [None, None, dac_factory.get_accuracy()]\n",
    "for label in precisions.keys():\n",
    "  dac_report[label] = [i[label] for i in precisions_recalls]\n",
    "\n",
    "df = DataFrame.from_dict(dac_report, orient='index', columns=['Precision', 'Recall', 'Accuracy'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evenly distribute the training data labelled as \"No\" and \"Yes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Label (Yes)  Label (No)  Ratio (Yes)\n",
       "Training Dataset           92         506     0.153846\n",
       "Test Dataset               39         111     0.260000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label (Yes)</th>\n      <th>Label (No)</th>\n      <th>Ratio (Yes)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Training Dataset</th>\n      <td>92</td>\n      <td>506</td>\n      <td>0.153846</td>\n    </tr>\n    <tr>\n      <th>Test Dataset</th>\n      <td>39</td>\n      <td>111</td>\n      <td>0.260000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "X_train = training_dataset[FEATURES]\n",
    "X_test = test_dataset[FEATURES]\n",
    "y_train = training_dataset[LABEL]\n",
    "y_true = test_dataset[LABEL]\n",
    "\n",
    "min_label_count = y_train.value_counts().min()\n",
    "labelled_yes = training_dataset.loc[training_dataset[LABEL] == 'Yes'].head(min_label_count)\n",
    "labelled_no = training_dataset.loc[training_dataset[LABEL] == 'No'].head(min_label_count)\n",
    "evenly_distrubted_training_dataset = pandas.concat([labelled_yes, labelled_no])\n",
    "\n",
    "# Shuffle the order, in order to properly train the model.\n",
    "evenly_distrubted_training_dataset = evenly_distrubted_training_dataset.sample(frac=1)\n",
    "\n",
    "X_train_evenly_dist = evenly_distrubted_training_dataset[FEATURES]\n",
    "y_train_evenly_dist = evenly_distrubted_training_dataset[LABEL]\n",
    "\n",
    "# Show the datasets value counts\n",
    "dataset_dict = {}\n",
    "dataset_dict['Training Dataset'] = len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"]), len(training_dataset.loc[training_dataset[LABEL] == \"No\"]), len(training_dataset.loc[training_dataset[LABEL] == \"Yes\"])/len(training_dataset)\n",
    "dataset_dict['Test Dataset'] = len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"]), len(test_dataset.loc[test_dataset[LABEL] == \"No\"]), len(test_dataset.loc[test_dataset[LABEL] == \"Yes\"])/len(test_dataset)\n",
    "df = DataFrame.from_dict(dataset_dict, orient='index', columns=['Label (Yes)', 'Label (No)', 'Ratio (Yes)'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "is_author_categories = [\n",
    "    False,  # 0 should come before 1 for numerical columns.\n",
    "    True\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            'body_count_vectorizer',\n",
    "            CountVectorizer(stop_words='english'),\n",
    "            'body'\n",
    "        ),\n",
    "        (\n",
    "            'dac_transformer',\n",
    "            OneHotEncoder(categories=[dac_labels]),\n",
    "            ['dialogue_act_classification_ml']\n",
    "        ),\n",
    "        (\n",
    "            'is_author_transformer',\n",
    "            OneHotEncoder(categories=[is_author_categories]),\n",
    "            ['comment_is_by_author']\n",
    "        ),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_count_vectorizer': 4,\n",
    "        'dac_transformer': 1,\n",
    "        'is_author_transformer': 2,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'CountVectorizer - SVC': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_svc.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'CountVectorizer - SVC (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            'body_tfidf_vectorizer',\n",
    "            TfidfVectorizer(stop_words='english', ngram_range=(1, 2)),\n",
    "            'body'\n",
    "        ),\n",
    "        (\n",
    "            'dac_transformer',\n",
    "            OneHotEncoder(categories=[dac_labels]),\n",
    "            ['dialogue_act_classification_ml']\n",
    "        ),\n",
    "        (\n",
    "            'is_author_transformer',\n",
    "            OneHotEncoder(categories=[is_author_categories]),\n",
    "            ['comment_is_by_author']\n",
    "        ),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_tfidf_vectorizer': 4,\n",
    "        'dac_transformer': 1,\n",
    "        'is_author_transformer': 2,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc = full_pipeline\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - SVC': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_svc.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - SVC (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Stemming - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "class StemmedCountVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('body_count_vectorizer', StemmedCountVectorizer(stop_words=None, ngram_range=(2, 2)), 'body'),\n",
    "        (\n",
    "            'dac_transformer',\n",
    "            OneHotEncoder(categories=[dac_labels]),\n",
    "            ['dialogue_act_classification_ml']\n",
    "        ),\n",
    "        (\n",
    "            'is_author_transformer',\n",
    "            OneHotEncoder(categories=[is_author_categories]),\n",
    "            ['comment_is_by_author']\n",
    "        ),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_count_vectorizer': 4,\n",
    "        'dac_transformer': 1,\n",
    "        'is_author_transformer': 2,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=1.2, probability=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc = full_pipeline\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Stemming - SVC': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_svc.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Stemming - SVC (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Lemmatization - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nlp import LemmaTokenizer\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            'body_tfidf_vectorizer',\n",
    "            TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', ngram_range=(1, 2)),\n",
    "            'body'\n",
    "        ),\n",
    "        (\n",
    "            'dac_transformer',\n",
    "            OneHotEncoder(categories=[dac_labels]),\n",
    "            ['dialogue_act_classification_ml']\n",
    "        ),\n",
    "        (\n",
    "            'is_author_transformer',\n",
    "            OneHotEncoder(categories=[is_author_categories]),\n",
    "            ['comment_is_by_author']\n",
    "        ),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'body_tfidf_vectorizer': 4,\n",
    "        'dac_transformer': 1,\n",
    "        'is_author_transformer': 2,\n",
    "    },\n",
    "    verbose=False)\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SVC(kernel='linear', C=0.1, probability=True))\n",
    "    ],\n",
    "    verbose=False)\n",
    "\n",
    "clf_svc = full_pipeline\n",
    "\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - SVC': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_svc.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - SVC (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Lemmatization - SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SGDClassifier(random_state=13))\n",
    "    ],\n",
    "    verbose=False)\n",
    "\n",
    "clf_sgd = full_pipeline\n",
    "\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "y_pred = clf_sgd.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - SGDClassifier': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_sgd.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_sgd.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - SGDClassifier (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Lemmatization - KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ],\n",
    "    verbose=False)\n",
    "\n",
    "clf_kneighbors = full_pipeline\n",
    "\n",
    "clf_kneighbors.fit(X_train, y_train)\n",
    "y_pred = clf_kneighbors.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - KNeighborsClassifier': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_kneighbors.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_kneighbors.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - KNeighborsClassifier (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Lemmatization - Ensemble Classifiers (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', BaggingClassifier(base_estimator=LogisticRegression(C=500000, solver='lbfgs'), max_samples=0.5, max_features=0.5))\n",
    "    ],\n",
    "    verbose=False)\n",
    "\n",
    "clf_ensemble = full_pipeline\n",
    "\n",
    "clf_ensemble.fit(X_train, y_train)\n",
    "y_pred = clf_ensemble.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - Ensemble Classifiers (Logistic Regression)': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_ensemble.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_ensemble.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - Ensemble Classifiers (Logistic Regression) (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Lemmatization - MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', MultinomialNB(fit_prior=True))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_multinominal_nb = full_pipeline\n",
    "\n",
    "clf_multinominal_nb.fit(X_train, y_train)\n",
    "y_pred = clf_multinominal_nb.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - MultinomialNB': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_multinominal_nb.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_multinominal_nb.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - MultinomialNB (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Lemmatization - LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', LogisticRegression(C=500000, solver='lbfgs'))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_logistic_regression = full_pipeline\n",
    "\n",
    "clf_logistic_regression.fit(X_train, y_train)\n",
    "y_pred = clf_logistic_regression.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - LogisticRegression': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_logistic_regression.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_logistic_regression.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - LogisticRegression (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - Lemmatization - DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', DecisionTreeClassifier(random_state=1, min_samples_split=0.25))],\n",
    "    verbose=False)\n",
    "\n",
    "clf_decision_tree = full_pipeline\n",
    "\n",
    "clf_decision_tree.fit(X_train, y_train)\n",
    "y_pred = clf_decision_tree.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - DecisionTree': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_decision_tree.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_decision_tree.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'TFIDF - Lemmatization - DecisionTree (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodeComprehensionClassifierFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from classifier import CodeComprehensionClassifierFactory\n",
    "\n",
    "clf_optimal = CodeComprehensionClassifierFactory.get_classifier(dac_labels)\n",
    "\n",
    "clf_optimal.fit(X_train, y_train)\n",
    "y_pred = clf_optimal.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'CodeComprehensionClassifierFactory': metrics.classification_report(y_true, y_pred, output_dict=True)})\n",
    "\n",
    "clf_optimal.fit(X_train_evenly_dist, y_train_evenly_dist)\n",
    "y_pred = clf_optimal.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'CodeComprehensionClassifierFactory (Evenly Distributed)': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "source": [
    "# Report Performance Before Grid Search (as it is time consuming)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           Algorithms  no_precision  \\\n",
       "0                               CountVectorizer - SVC      0.798450   \n",
       "1          CountVectorizer - SVC (Evenly Distributed)      0.864583   \n",
       "2                                         TFIDF - SVC      0.768116   \n",
       "3                    TFIDF - SVC (Evenly Distributed)      0.876404   \n",
       "4                              TFIDF - Stemming - SVC      0.767606   \n",
       "5         TFIDF - Stemming - SVC (Evenly Distributed)      0.890411   \n",
       "6                         TFIDF - Lemmatization - SVC      0.845528   \n",
       "7    TFIDF - Lemmatization - SVC (Evenly Distributed)      0.897959   \n",
       "8               TFIDF - Lemmatization - SGDClassifier      0.902655   \n",
       "9   TFIDF - Lemmatization - SGDClassifier (Evenly ...      0.887755   \n",
       "10       TFIDF - Lemmatization - KNeighborsClassifier      0.776978   \n",
       "11  TFIDF - Lemmatization - KNeighborsClassifier (...      0.906977   \n",
       "12  TFIDF - Lemmatization - Ensemble Classifiers (...      0.846774   \n",
       "13  TFIDF - Lemmatization - Ensemble Classifiers (...      0.892473   \n",
       "14              TFIDF - Lemmatization - MultinomialNB      0.740000   \n",
       "15  TFIDF - Lemmatization - MultinomialNB (Evenly ...      0.883721   \n",
       "16         TFIDF - Lemmatization - LogisticRegression      0.846774   \n",
       "17  TFIDF - Lemmatization - LogisticRegression (Ev...      0.896907   \n",
       "18               TFIDF - Lemmatization - DecisionTree      0.928571   \n",
       "19  TFIDF - Lemmatization - DecisionTree (Evenly D...      0.927835   \n",
       "20                 CodeComprehensionClassifierFactory      0.846774   \n",
       "21  CodeComprehensionClassifierFactory (Evenly Dis...      0.896907   \n",
       "\n",
       "    no_recall  no_f1_score  yes_precision  yes_recall  yes_f1_score  Accuracy  \n",
       "0    0.927928     0.858333       0.619048    0.333333      0.433333  0.773333  \n",
       "1    0.747748     0.801932       0.481481    0.666667      0.559140  0.726667  \n",
       "2    0.954955     0.851406       0.583333    0.179487      0.274510  0.753333  \n",
       "3    0.702703     0.780000       0.459016    0.717949      0.560000  0.706667  \n",
       "4    0.981982     0.861660       0.750000    0.153846      0.255319  0.766667  \n",
       "5    0.585586     0.706522       0.402597    0.794872      0.534483  0.640000  \n",
       "6    0.936937     0.888889       0.740741    0.512821      0.606061  0.826667  \n",
       "7    0.792793     0.842105       0.557692    0.743590      0.637363  0.780000  \n",
       "8    0.918919     0.910714       0.756757    0.717949      0.736842  0.866667  \n",
       "9    0.783784     0.832536       0.538462    0.717949      0.615385  0.766667  \n",
       "10   0.972973     0.864000       0.727273    0.205128      0.320000  0.773333  \n",
       "11   0.702703     0.791878       0.484375    0.794872      0.601942  0.726667  \n",
       "12   0.945946     0.893617       0.769231    0.512821      0.615385  0.833333  \n",
       "13   0.747748     0.813725       0.508772    0.743590      0.604167  0.746667  \n",
       "14   1.000000     0.850575       0.000000    0.000000      0.000000  0.740000  \n",
       "15   0.684685     0.771574       0.453125    0.743590      0.563107  0.700000  \n",
       "16   0.945946     0.893617       0.769231    0.512821      0.615385  0.833333  \n",
       "17   0.783784     0.836538       0.547170    0.743590      0.630435  0.773333  \n",
       "18   0.819820     0.870813       0.615385    0.820513      0.703297  0.820000  \n",
       "19   0.810811     0.865385       0.603774    0.820513      0.695652  0.813333  \n",
       "20   0.945946     0.893617       0.769231    0.512821      0.615385  0.833333  \n",
       "21   0.783784     0.836538       0.547170    0.743590      0.630435  0.773333  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithms</th>\n      <th>no_precision</th>\n      <th>no_recall</th>\n      <th>no_f1_score</th>\n      <th>yes_precision</th>\n      <th>yes_recall</th>\n      <th>yes_f1_score</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CountVectorizer - SVC</td>\n      <td>0.798450</td>\n      <td>0.927928</td>\n      <td>0.858333</td>\n      <td>0.619048</td>\n      <td>0.333333</td>\n      <td>0.433333</td>\n      <td>0.773333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CountVectorizer - SVC (Evenly Distributed)</td>\n      <td>0.864583</td>\n      <td>0.747748</td>\n      <td>0.801932</td>\n      <td>0.481481</td>\n      <td>0.666667</td>\n      <td>0.559140</td>\n      <td>0.726667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TFIDF - SVC</td>\n      <td>0.768116</td>\n      <td>0.954955</td>\n      <td>0.851406</td>\n      <td>0.583333</td>\n      <td>0.179487</td>\n      <td>0.274510</td>\n      <td>0.753333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TFIDF - SVC (Evenly Distributed)</td>\n      <td>0.876404</td>\n      <td>0.702703</td>\n      <td>0.780000</td>\n      <td>0.459016</td>\n      <td>0.717949</td>\n      <td>0.560000</td>\n      <td>0.706667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TFIDF - Stemming - SVC</td>\n      <td>0.767606</td>\n      <td>0.981982</td>\n      <td>0.861660</td>\n      <td>0.750000</td>\n      <td>0.153846</td>\n      <td>0.255319</td>\n      <td>0.766667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>TFIDF - Stemming - SVC (Evenly Distributed)</td>\n      <td>0.890411</td>\n      <td>0.585586</td>\n      <td>0.706522</td>\n      <td>0.402597</td>\n      <td>0.794872</td>\n      <td>0.534483</td>\n      <td>0.640000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>TFIDF - Lemmatization - SVC</td>\n      <td>0.845528</td>\n      <td>0.936937</td>\n      <td>0.888889</td>\n      <td>0.740741</td>\n      <td>0.512821</td>\n      <td>0.606061</td>\n      <td>0.826667</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>TFIDF - Lemmatization - SVC (Evenly Distributed)</td>\n      <td>0.897959</td>\n      <td>0.792793</td>\n      <td>0.842105</td>\n      <td>0.557692</td>\n      <td>0.743590</td>\n      <td>0.637363</td>\n      <td>0.780000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>TFIDF - Lemmatization - SGDClassifier</td>\n      <td>0.902655</td>\n      <td>0.918919</td>\n      <td>0.910714</td>\n      <td>0.756757</td>\n      <td>0.717949</td>\n      <td>0.736842</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>TFIDF - Lemmatization - SGDClassifier (Evenly ...</td>\n      <td>0.887755</td>\n      <td>0.783784</td>\n      <td>0.832536</td>\n      <td>0.538462</td>\n      <td>0.717949</td>\n      <td>0.615385</td>\n      <td>0.766667</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>TFIDF - Lemmatization - KNeighborsClassifier</td>\n      <td>0.776978</td>\n      <td>0.972973</td>\n      <td>0.864000</td>\n      <td>0.727273</td>\n      <td>0.205128</td>\n      <td>0.320000</td>\n      <td>0.773333</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>TFIDF - Lemmatization - KNeighborsClassifier (...</td>\n      <td>0.906977</td>\n      <td>0.702703</td>\n      <td>0.791878</td>\n      <td>0.484375</td>\n      <td>0.794872</td>\n      <td>0.601942</td>\n      <td>0.726667</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>TFIDF - Lemmatization - Ensemble Classifiers (...</td>\n      <td>0.846774</td>\n      <td>0.945946</td>\n      <td>0.893617</td>\n      <td>0.769231</td>\n      <td>0.512821</td>\n      <td>0.615385</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>TFIDF - Lemmatization - Ensemble Classifiers (...</td>\n      <td>0.892473</td>\n      <td>0.747748</td>\n      <td>0.813725</td>\n      <td>0.508772</td>\n      <td>0.743590</td>\n      <td>0.604167</td>\n      <td>0.746667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>TFIDF - Lemmatization - MultinomialNB</td>\n      <td>0.740000</td>\n      <td>1.000000</td>\n      <td>0.850575</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.740000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>TFIDF - Lemmatization - MultinomialNB (Evenly ...</td>\n      <td>0.883721</td>\n      <td>0.684685</td>\n      <td>0.771574</td>\n      <td>0.453125</td>\n      <td>0.743590</td>\n      <td>0.563107</td>\n      <td>0.700000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>TFIDF - Lemmatization - LogisticRegression</td>\n      <td>0.846774</td>\n      <td>0.945946</td>\n      <td>0.893617</td>\n      <td>0.769231</td>\n      <td>0.512821</td>\n      <td>0.615385</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>TFIDF - Lemmatization - LogisticRegression (Ev...</td>\n      <td>0.896907</td>\n      <td>0.783784</td>\n      <td>0.836538</td>\n      <td>0.547170</td>\n      <td>0.743590</td>\n      <td>0.630435</td>\n      <td>0.773333</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>TFIDF - Lemmatization - DecisionTree</td>\n      <td>0.928571</td>\n      <td>0.819820</td>\n      <td>0.870813</td>\n      <td>0.615385</td>\n      <td>0.820513</td>\n      <td>0.703297</td>\n      <td>0.820000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>TFIDF - Lemmatization - DecisionTree (Evenly D...</td>\n      <td>0.927835</td>\n      <td>0.810811</td>\n      <td>0.865385</td>\n      <td>0.603774</td>\n      <td>0.820513</td>\n      <td>0.695652</td>\n      <td>0.813333</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>CodeComprehensionClassifierFactory</td>\n      <td>0.846774</td>\n      <td>0.945946</td>\n      <td>0.893617</td>\n      <td>0.769231</td>\n      <td>0.512821</td>\n      <td>0.615385</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>CodeComprehensionClassifierFactory (Evenly Dis...</td>\n      <td>0.896907</td>\n      <td>0.783784</td>\n      <td>0.836538</td>\n      <td>0.547170</td>\n      <td>0.743590</td>\n      <td>0.630435</td>\n      <td>0.773333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "x = [next(iter(report.keys())) for report in report_dict_list]\n",
    "\n",
    "df = DataFrame({\n",
    "    'Algorithms': x,\n",
    "    'no_precision': [next(iter(report.values()))['No']['precision'] for report in report_dict_list],\n",
    "    'no_recall': [next(iter(report.values()))['No']['recall'] for report in report_dict_list],\n",
    "    'no_f1_score': [next(iter(report.values()))['No']['f1-score'] for report in report_dict_list],\n",
    "    'yes_precision': [next(iter(report.values()))['Yes']['precision'] for report in report_dict_list],\n",
    "    'yes_recall': [next(iter(report.values()))['Yes']['recall'] for report in report_dict_list],\n",
    "    'yes_f1_score': [next(iter(report.values()))['Yes']['f1-score'] for report in report_dict_list],\n",
    "    'Accuracy': [next(iter(report.values()))['accuracy'] for report in report_dict_list]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', column_transformer),\n",
    "        ('classifier', SGDClassifier(random_state=13))],\n",
    "    verbose=False)\n",
    "\n",
    "yes_f1_scorer = metrics.make_scorer(metrics.f1_score, pos_label=\"Yes\")\n",
    "\n",
    "grid_search_cv_params = [\n",
    "    {'preprocessor__body_tfidf_vectorizer__tokenizer': [None, LemmaTokenizer()]},\n",
    "    {'preprocessor__body_tfidf_vectorizer__stop_words': [None, 'english']},\n",
    "    {'preprocessor__body_tfidf_vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 5), (2, 2), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5)]},\n",
    "    {\n",
    "        'preprocessor__transformer_weights': [\n",
    "            {'body_tfidf_vectorizer': 4, 'dac_transformer': 1, 'is_author_transformer': 2},\n",
    "            # {'body_tfidf_vectorizer': 1, 'dac_transformer': 1, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 1, 'dac_transformer': 6, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 1, 'dac_transformer': 6, 'is_author_transformer': 6},\n",
    "            # {'body_tfidf_vectorizer': 1, 'dac_transformer': 6, 'is_author_transformer': 100},\n",
    "            # {'body_tfidf_vectorizer': 1, 'dac_transformer': 100, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 1, 'dac_transformer': 100, 'is_author_transformer': 6},\n",
    "            # {'body_tfidf_vectorizer': 1, 'dac_transformer': 100, 'is_author_transformer': 100},\n",
    "            # {'body_tfidf_vectorizer': 4, 'dac_transformer': 1, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 4, 'dac_transformer': 6, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 4, 'dac_transformer': 6, 'is_author_transformer': 6},\n",
    "            # {'body_tfidf_vectorizer': 4, 'dac_transformer': 6, 'is_author_transformer': 100},\n",
    "            # {'body_tfidf_vectorizer': 4, 'dac_transformer': 100, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 4, 'dac_transformer': 100, 'is_author_transformer': 6},\n",
    "            # {'body_tfidf_vectorizer': 4, 'dac_transformer': 100, 'is_author_transformer': 100},          \n",
    "            # {'body_tfidf_vectorizer': 6, 'dac_transformer': 1, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 6, 'dac_transformer': 6, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 6, 'dac_transformer': 6, 'is_author_transformer': 6},\n",
    "            # {'body_tfidf_vectorizer': 6, 'dac_transformer': 6, 'is_author_transformer': 100},\n",
    "            # {'body_tfidf_vectorizer': 6, 'dac_transformer': 100, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 6, 'dac_transformer': 100, 'is_author_transformer': 6},\n",
    "            # {'body_tfidf_vectorizer': 6, 'dac_transformer': 100, 'is_author_transformer': 100},\n",
    "            # {'body_tfidf_vectorizer': 100, 'dac_transformer': 1, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 100, 'dac_transformer': 6, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 100, 'dac_transformer': 6, 'is_author_transformer': 6},\n",
    "            # {'body_tfidf_vectorizer': 100, 'dac_transformer': 6, 'is_author_transformer': 100},\n",
    "            # {'body_tfidf_vectorizer': 100, 'dac_transformer': 100, 'is_author_transformer': 1},\n",
    "            # {'body_tfidf_vectorizer': 100, 'dac_transformer': 100, 'is_author_transformer': 6},\n",
    "        ]\n",
    "    },\n",
    "    # {'classifier__min_samples_split': [2, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]},\n",
    "    # {'classifier__min_samples_leaf': [1, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]},\n",
    "    # {'classifier__min_weight_fraction_leaf': [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]},\n",
    "    # {'classifier__max_features': [None, 1, 2, 5, 10, 'auto', 'sqrt', 'log2']},\n",
    "    {'classifier__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']},\n",
    "    {'classifier__penalty': ['l2', 'l1', 'elasticnet']},\n",
    "    {'classifier__class_weight': [None, 'balanced', {'Yes': 0.175, 'No': 0.825}]},\n",
    "    {'classifier__shuffle': [True, False]},\n",
    "    # {'classifier__learning_rate': ['optimal', 'constant', 'adaptive']},\n",
    "    {'classifier__early_stopping': [True, False]},\n",
    "    {'classifier__random_state': [1, 2, 5, 10, 13, 100, 1000, 10000]},\n",
    "]\n",
    "clf_grid_search_cv = GridSearchCV(full_pipeline, param_grid=grid_search_cv_params, cv=5, scoring=yes_f1_scorer, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "clf_grid_search_cv.fit(X_train, y_train)\n",
    "clf_grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(clf_grid_search_cv.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf_grid_search_cv.predict(X_test)\n",
    "\n",
    "report = metrics.classification_report(y_true, y_pred, digits=8)\n",
    "report_dict_list.append({'GridSearch': metrics.classification_report(y_true, y_pred, output_dict=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Result Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "x = [next(iter(report.keys())) for report in report_dict_list]\n",
    "\n",
    "df = DataFrame({\n",
    "    'Algorithms': x,\n",
    "    'no_precision': [next(iter(report.values()))['No']['precision'] for report in report_dict_list],\n",
    "    'no_recall': [next(iter(report.values()))['No']['recall'] for report in report_dict_list],\n",
    "    'no_f1_score': [next(iter(report.values()))['No']['f1-score'] for report in report_dict_list],\n",
    "    'yes_precision': [next(iter(report.values()))['Yes']['precision'] for report in report_dict_list],\n",
    "    'yes_recall': [next(iter(report.values()))['Yes']['recall'] for report in report_dict_list],\n",
    "    'yes_f1_score': [next(iter(report.values()))['Yes']['f1-score'] for report in report_dict_list],\n",
    "    'Accuracy': [next(iter(report.values()))['accuracy'] for report in report_dict_list]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyplot.style.context('seaborn-white'):\n",
    "    df.plot.bar(x='Algorithms', y='yes_f1_score', rot=90, title='Algorithms v.s. F1-Score (Label \"Yes\")', color='red', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='yes_precision', rot=90, title='Algorithms v.s. Precision (Label \"Yes\")', color='orange', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='yes_recall', rot=90, title='Algorithms v.s. Recall (Label \"Yes\")', color='brown', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='no_f1_score', rot=90, title='Algorithms v.s. F1-Score (Label \"No\")', color='green', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='no_precision', rot=90, title='Algorithms v.s. Precision (Label \"No\")', color='blue', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='no_recall', rot=90, title='Algorithms v.s. Recall (Label \"No\")', color='magenta', legend=False)\n",
    "    df.plot.bar(x='Algorithms', y='Accuracy', rot=90, title='Algorithms v.s. Accurracy', color='purple', legend=False)\n",
    "\n",
    "    # axes = df.plot.bar(rot=90, title=\"Algorithms Performance\", subplots=True)\n",
    "\n",
    "    pyplot.show(block=False)"
   ]
  }
 ]
}